# ğŸ“§ Google Email Scraper Dashboard

A full-stack dashboard for managing and monitoring a **Playwright-based Google Email Scraper** with live logs, concurrent control, and CAPTCHA handling via **NopeCHA** â€” now organized into only **two folders**: `frontend/` and `backend/`.

---

## ğŸ§© Overview

This project combines a **React + Vite frontend** and an **Express.js backend** with integrated **Playwright automation**, enabling CSV-based query uploads, concurrent scraping, and real-time monitoring.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       React UI         â”‚
â”‚ - Upload CSV           â”‚
â”‚ - Set BROWSERS & TABS  â”‚
â”‚ - Start/Stop scraper   â”‚
â”‚ - Live logs + progress â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚ REST + WebSocket
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Express API + Scraper â”‚
â”‚ - /start-scraper        â”‚
â”‚ - /stop-scraper         â”‚
â”‚ - /status               â”‚
â”‚ - /upload-input         â”‚
â”‚ - /logs (socket.io)     â”‚
â”‚ - Playwright automation â”‚
â”‚ - NopeCHA CAPTCHA solverâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âš™ï¸ Features

* ğŸ”„ **Start / Stop** scraper from dashboard
* ğŸ§® **Control concurrency** (`BROWSERS` + `TABS_PER_BROWSER`)
* ğŸ“¤ **Upload CSV** queries dynamically
* ğŸ“¡ **Real-time logs** via WebSocket (Socket.IO)
* ğŸ“ˆ **Progress tracking**
* ğŸ¤– **NopeCHA CAPTCHA solver** integration
* â˜ï¸ **Supabase** data storage (optional)
* ğŸ§± **Safe CSV I/O** (tolerant input, structured output)

---

## ğŸ§± Folder Structure

```
google-email-scraper-dashboard/
â”‚
â”œâ”€â”€ frontend/                          # ğŸ–¥ï¸ React + Vite Frontend
â”‚   â”œâ”€â”€ public/
â”‚   â”‚   â””â”€â”€ index.html
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ ControlPanel.jsx       # Concurrency controls + start/stop buttons
â”‚   â”‚   â”‚   â”œâ”€â”€ UploadCSV.jsx          # CSV uploader UI
â”‚   â”‚   â”‚   â”œâ”€â”€ LogViewer.jsx          # Real-time log viewer
â”‚   â”‚   â”‚   â”œâ”€â”€ ProgressBar.jsx        # Scraping progress indicator
â”‚   â”‚   â”‚   â””â”€â”€ StatusCard.jsx         # Shows PID, uptime, and scraper state
â”‚   â”‚   â”œâ”€â”€ hooks/
â”‚   â”‚   â”‚   â””â”€â”€ useScraperSocket.js    # Custom Socket.io hook
â”‚   â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”‚   â””â”€â”€ scraperApi.js          # API helper functions
â”‚   â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”‚   â””â”€â”€ Dashboard.jsx
â”‚   â”‚   â”œâ”€â”€ App.jsx
â”‚   â”‚   â”œâ”€â”€ main.jsx
â”‚   â”‚   â””â”€â”€ styles/
â”‚   â”‚       â””â”€â”€ app.css
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ vite.config.js
â”‚   â””â”€â”€ README.md
â”‚
â””â”€â”€ backend/                           # âš™ï¸ Express + Scraper Backend
    â”œâ”€â”€ index.js                       # Entry point (Express + Socket.IO)
    â”œâ”€â”€ routes/
    â”‚   â”œâ”€â”€ scraper.js                 # /start, /stop, /status
    â”‚   â”œâ”€â”€ upload.js                  # /upload-input
    â”œâ”€â”€ scraper/                       # ğŸ¤– Playwright Scraper Logic
    â”‚   â”œâ”€â”€ google_email_scraper.js    # Main Playwright script
    â”‚   â”œâ”€â”€ solver.js                  # NopeCHA CAPTCHA integration
    â”‚   â”œâ”€â”€ helpers/
    â”‚   â”‚   â”œâ”€â”€ readCSV.js             # CSV reader utility
    â”‚   â”‚   â”œâ”€â”€ saveCSV.js             # Write output CSV
    â”‚   â”‚   â”œâ”€â”€ supabaseClient.js      # Supabase integration
    â”‚   â”‚   â””â”€â”€ limiter.js             # Bottleneck concurrency control
    â”‚   â””â”€â”€ config/
    â”‚       â””â”€â”€ scraperConfig.js       # Scraper settings (timeouts, retries)
    â”œâ”€â”€ utils/
    â”‚   â”œâ”€â”€ processManager.js          # Manage scraper process lifecycle
    â”‚   â””â”€â”€ logger.js                  # Centralized log broadcasting
    â”œâ”€â”€ data/
    â”‚   â”œâ”€â”€ input.csv                  # Uploaded input
    â”‚   â”œâ”€â”€ output.csv                 # Scraper results
    â”‚   â””â”€â”€ logs/
    â”‚       â””â”€â”€ run_2025-10-30.log     # Daily log output
    â”œâ”€â”€ middleware/
    â”‚   â””â”€â”€ errorHandler.js
    â”œâ”€â”€ package.json
    â””â”€â”€ README.md
```

---

## ğŸ§  Environment Variables

| Variable           | Example                   | Description                   |
| ------------------ | ------------------------- | ----------------------------- |
| `BROWSERS`         | `2`                       | Number of Playwright browsers |
| `TABS_PER_BROWSER` | `2`                       | Tabs per browser instance     |
| `SUPABASE_URL`     | `https://xyz.supabase.co` | Supabase project URL          |
| `SUPABASE_KEY`     | `your-key`                | Supabase API key              |
| `NOPECHA_API_KEY`  | `your-nopecha-key`        | CAPTCHA solver API key        |
| `HEADLESS`         | `true`                    | Run Playwright headless       |
| `PORT`             | `5000`                    | Backend server port           |

---

## ğŸš€ Getting Started

### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/yourusername/google-email-scraper-dashboard.git
cd google-email-scraper-dashboard
```

### 2ï¸âƒ£ Install Dependencies

```bash
cd backend
npm install
npm run playwright:install
cd ../frontend
npm install
```

### 3ï¸âƒ£ Configure `.env`

Create `.env` in the **backend** directory:

```bash
HEADLESS=true
BROWSERS=2
TABS_PER_BROWSER=2
SUPABASE_URL=https://yourproject.supabase.co
SUPABASE_KEY=your-supabase-key
NOPECHA_API_KEY=your-nopecha-key
PORT=5000
```

### 4ï¸âƒ£ Start Backend

```bash
cd backend
npm run dev
```

### 5ï¸âƒ£ Start Frontend

```bash
cd frontend
npm run dev
```

Access your dashboard at ğŸ‘‰ [http://localhost:5173](http://localhost:5173)

---

## ğŸ–¥ï¸ Dashboard Features

| Feature                   | Description                      |
| ------------------------- | -------------------------------- |
| ğŸ“‚ **Upload CSV**         | Upload query list for scraping   |
| âš™ï¸ **Set concurrency**    | Configure browsers and tabs      |
| â–¶ï¸ **Start/Stop scraper** | Start or stop scraping instantly |
| ğŸ§¾ **Live Logs**          | Stream real-time log updates     |
| ğŸ“Š **Progress Bar**       | Track progress dynamically       |
| ğŸ§  **Status Card**        | Show scraper PID, uptime, state  |

---

## ğŸŒ API Endpoints (Express)

| Method | Route            | Description                |
| ------ | ---------------- | -------------------------- |
| `POST` | `/start-scraper` | Start scraper with config  |
| `POST` | `/stop-scraper`  | Stop running scraper       |
| `GET`  | `/status`        | Get current scraper status |
| `POST` | `/upload-input`  | Upload input CSV           |
| `WS`   | `/logs`          | Real-time WebSocket logs   |

---

## âš¡ WebSocket Events

| Event      | Direction       | Example                         |
| ---------- | --------------- | ------------------------------- |
| `log`      | Server â†’ Client | `"âœ… [query] 5 emails found"`    |
| `progress` | Server â†’ Client | `{ completed: 45, total: 100 }` |
| `status`   | Server â†’ Client | `"running"` / `"stopped"`       |

---

## ğŸ§° Tools & Libraries

| Component | Library                           |
| --------- | --------------------------------- |
| Frontend  | React + Vite + Socket.io-client   |
| Backend   | Express + Socket.IO + Multer      |
| Scraper   | Playwright + Bottleneck + NopeCHA |
| Database  | Supabase                          |
| CSV I/O   | Node fs + fast-csv                |

---

## ï¿½ Local Tips

- Run `npm run dev` inside both `backend/` and `frontend/` whenever you want to work on the project. Stop each with `Ctrl + C`.
- The backend serves logs over Socket.IO. Keep that terminal open to continue receiving updates in the UI.
- Playwright browsers are installed by `npm run playwright:install`. Re-run it if you update Playwright or switch machines.
- If ports 5000 or 5173 are busy, stop other apps or export a different `PORT` for the backend and update the frontend `.env` proxy setting.

---

## âœ… Summary

| Layer        | Purpose                              |
| ------------ | ------------------------------------ |
| **Frontend** | User interface for scraper control   |
| **Backend**  | REST API + WebSocket + Scraper logic |
| **Scraper**  | Playwright automation with NopeCHA   |
| **Storage**  | Supabase + CSV for persistent data   |

---